{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f187ddc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy\n",
    "import requests\n",
    "\n",
    "# We temporarily add the required programs to PATH so we can run them via the console.\n",
    "# Ensure the install_dependencies.sh script has run successfully.\n",
    "# Look at the README file if any issues occur in building RIVET.\n",
    "os.environ[\"PATH\"] += os.pathsep + os.getcwd() + \"/dependencies/rivet/build/\" \n",
    "os.environ[\"PATH\"] += os.pathsep + os.getcwd() + \"/dependencies/hera/geom_bottleneck/build/example/\"\n",
    "\n",
    "endings = ['251256', '261034', '291467', '281264', '351899', '361446', '401224']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f85dc9f6-128f-4113-9e9e-68f2244b6eb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DOWNLOAD DATA\n",
    "url = 'http://users.cecs.anu.edu.au/~bdm/data/'\n",
    "for e in endings:\n",
    "  r = requests.get(url + \"sr\" + e + \".g6\", allow_redirects=True)\n",
    "  filename = \"./data/sr\" + e + \".g6\"\n",
    "  os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "  open(filename, 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f185f23-7dda-4dbb-afe8-7a0508587893",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_filtration(vert_vals, G, name, xlabel, ylabel):\n",
    "    \"\"\"\n",
    "    Input: vert_vals - A filtration function V -> R^2, inthe form of an  |V| x 2 matrix\n",
    "            G - A networkx graph\n",
    "            name - the name of the file to save the filtration\n",
    "    Output: Clique complex + bifiltration\n",
    "    \"\"\"\n",
    "\n",
    "    # Do vertices first\n",
    "    filename = \"./bifiltrations/\" + name + \".txt\"\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"--datatype bifiltration\\n\")\n",
    "        f.write(\"--xlabel \" + xlabel + \"\\n\")\n",
    "        f.write(\"--ylabel \" + ylabel + \"\\n\\n\")\n",
    "    \n",
    "        for c in nx.enumerate_all_cliques(G):\n",
    "            line = \" \".join(map(str, c)) + \" ; \"\n",
    "            new_vals = np.maximum.reduce([vert_vals[v] for v in c])\n",
    "            line +=  \" \".join(map(str, new_vals)) + \"\\n\"\n",
    "            f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc610da2-97f4-442c-a56c-3f05b6d74d1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hks(evals, t, vertex):\n",
    "    # Computes the heat kernel signature of a graph with parameter t, given the eigendecomposition in evals.\n",
    "    return sum([np.exp(-t * lam) * psi[vertex] * psi[vertex] for (lam, psi) in evals]).real\n",
    "\n",
    "\n",
    "# Load graphs from file after being downloaded\n",
    "# Compute the vertex features needed\n",
    "graphs = {}\n",
    "for e in endings:\n",
    "    graph_list = nx.read_graph6(\"data/sr\"+e+\".g6\")\n",
    "    graphs[e] = []\n",
    "    random = np.random.rand(int(e[:2])) \n",
    "    for G in graph_list:\n",
    "        edecomp = np.linalg.eig(nx.normalized_laplacian_matrix(G).toarray())\n",
    "        transp = sorted(zip(edecomp[0], edecomp[1]), key=lambda t: t[0])\n",
    "        hks_G = hks(transp, 1, range(len(transp)))\n",
    "        graphs[e].append({\"graph\": G, \"hks\" : hks_G, \"random\" : random})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20535bf3-1a78-476a-b922-30b821463463",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute the persistent homology of each graph, via the rivet_console program added to PATH\n",
    "H0_persistence_modules = []\n",
    "H1_persistence_modules = []\n",
    "for e in endings:\n",
    "    e_H0_pers_modules = []\n",
    "    e_H1_pers_modules = []\n",
    "    for (i, G) in enumerate(graphs[e]):\n",
    "        filename = e + \"_\" + str(i)\n",
    "        build_filtration( list(zip(G[\"hks\"], G[\"random\"])) , G[\"graph\"], filename, \"hks\", \"random\")\n",
    "        os.system(\"rivet_console ./bifiltrations/{}.txt ./bifiltrations/{}.rivet  --homology 0 --xbins 100 --ybins 100\".format(filename, filename + \"_0\"))\n",
    "        os.system(\"rivet_console ./bifiltrations/{}.txt ./bifiltrations/{}.rivet  --homology 1 --xbins 100 --ybins 100\".format(filename, filename + \"_1\"))\n",
    "        with open(\"./bifiltrations/{}.rivet\".format(filename + \"_0\"), 'rb') as f:\n",
    "            computed_data = f.read()\n",
    "            e_H0_pers_modules.append(computed_data)\n",
    "        with open(\"./bifiltrations/{}.rivet\".format(filename + \"_1\"), 'rb') as f:\n",
    "            computed_data = f.read()\n",
    "            e_H1_pers_modules.append(computed_data)\n",
    "    H0_persistence_modules.append(e_H0_pers_modules)\n",
    "    H1_persistence_modules.append(e_H1_pers_modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972b7bcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matching_distance\n",
    "\n",
    "# Now compute the accuracy to which the fibered barcodes on a 10 x 10 grid of lines\n",
    "# distinguish pairs of graphs in the same collection.\n",
    "\n",
    "# This might take a few hours to run, depending on your computer. Hera is written in python and is very slow.\n",
    "\n",
    "# distance threshold to declare two barcodes distinct\n",
    "eps = 1e-8\n",
    "\n",
    "H0_accuracy = []\n",
    "for (i, e) in enumerate(endings):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for (j1, P1) in enumerate(H0_persistence_modules[i]):\n",
    "        for j2 in range(j1):\n",
    "            total+=1\n",
    "            P2 = H0_persistence_modules[i][j2]\n",
    "            if matching_distance.matching_distance(P1, P2, grid_size=10, normalize=True) > eps:\n",
    "                correct += 1\n",
    "    H0_accuracy.append( correct / total )\n",
    "\n",
    "H1_accuracy = []\n",
    "for (i, e) in enumerate(endings):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for (j1, P1) in enumerate(H1_persistence_modules[i]):\n",
    "        for j2 in range(j1):\n",
    "            total+=1\n",
    "            P2 = H1_persistence_modules[i][j2]\n",
    "            if matching_distance.matching_distance(P1, P2, grid_size=10, normalize=True) > eps:\n",
    "                correct += 1\n",
    "    H1_accuracy.append( correct / total )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9feb8a82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Print the results of the previous computation.\n",
    "print(H0_accuracy)\n",
    "print(H1_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
